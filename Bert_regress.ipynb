{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use only one GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch, random\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pre-train bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nghuyong/ernie-3.0-base-zh were not used when initializing ErnieForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at nghuyong/ernie-3.0-base-zh and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"hfl/chinese-roberta-wwm-ext\" # \"hfl/chinese-roberta-wwm-ext-large\" requires at least 16GB \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# By setting num_labels to 1 will automatically enable regression mode\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels = 1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/train.csv\"\n",
    "data = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_30893</th>\n",
       "      <td>罪犯张都树，男，1994年xx月xx日出生，汉族，山西省浑源人，现在山西省太原第三监狱服刑，...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_45279</th>\n",
       "      <td>罪犯池杰，男，1992年xx月xx日出生，汉族，福建省大田县人，初中文化，原住福建省大田县建...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_16398</th>\n",
       "      <td>罪犯林凯利，男，1995年xx月xx日出生于广东省清远市英德市横石水镇，汉族。现在湖南省未成...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_13653</th>\n",
       "      <td>罪犯黄贝策，男，1965年xx月xx日出生，汉族，广西壮族自治区宾阳县人，初中文化，原住广西...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_13748</th>\n",
       "      <td>罪犯王卡康，男，1968年xx月xx日出生，汉族，初中文化，捕前系哈尔滨铁路局海拉尔列车段整...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_11284</th>\n",
       "      <td>罪犯李伟，男，1997年xx月xx日出生，汉族，海南省万宁市人，初中文化，农民，捕前住海南省...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_44732</th>\n",
       "      <td>罪犯欧九固，男，1972年xx月xx日生，汉族，广西壮族自治区蒙山县人，初中文化，原住广西壮...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_38158</th>\n",
       "      <td>罪犯姜群，男，1971年xx月xx日出生，汉族，出生地辽宁省沈阳市，初中文化，现在辽宁省沈阳...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_860</th>\n",
       "      <td>罪犯吴礼善，男，1973年xx月xx日出生，汉族，广西鹿寨县人，小学文化，原住广西鹿寨县导江...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_15795</th>\n",
       "      <td>罪犯张玉芳，男，汉族，1966年xx月xx日出生于黑龙江省林甸县，高中文化。现于黑龙江省呼兰...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       fact  label\n",
       "id                                                                \n",
       "id_30893  罪犯张都树，男，1994年xx月xx日出生，汉族，山西省浑源人，现在山西省太原第三监狱服刑，...      8\n",
       "id_45279  罪犯池杰，男，1992年xx月xx日出生，汉族，福建省大田县人，初中文化，原住福建省大田县建...      7\n",
       "id_16398  罪犯林凯利，男，1995年xx月xx日出生于广东省清远市英德市横石水镇，汉族。现在湖南省未成...     12\n",
       "id_13653  罪犯黄贝策，男，1965年xx月xx日出生，汉族，广西壮族自治区宾阳县人，初中文化，原住广西...      6\n",
       "id_13748  罪犯王卡康，男，1968年xx月xx日出生，汉族，初中文化，捕前系哈尔滨铁路局海拉尔列车段整...      7\n",
       "...                                                     ...    ...\n",
       "id_11284  罪犯李伟，男，1997年xx月xx日出生，汉族，海南省万宁市人，初中文化，农民，捕前住海南省...      0\n",
       "id_44732  罪犯欧九固，男，1972年xx月xx日生，汉族，广西壮族自治区蒙山县人，初中文化，原住广西壮...      9\n",
       "id_38158  罪犯姜群，男，1971年xx月xx日出生，汉族，出生地辽宁省沈阳市，初中文化，现在辽宁省沈阳...      9\n",
       "id_860    罪犯吴礼善，男，1973年xx月xx日出生，汉族，广西鹿寨县人，小学文化，原住广西鹿寨县导江...     12\n",
       "id_15795  罪犯张玉芳，男，汉族，1966年xx月xx日出生于黑龙江省林甸县，高中文化。现于黑龙江省呼兰...      5\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, train_size=0.8, random_state=42)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text\n",
    "train_encodings = tokenizer(train_data.fact.tolist(), truncation=True, padding=True, max_length=512)\n",
    "valid_encodings = tokenizer(val_data.fact.tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it torch friendly\n",
    "class TorchData(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels = None, length = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        # If predicting then no label given\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "            item[\"labels\"] = float(item[\"labels\"])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.length is not None:\n",
    "            return self.length\n",
    "        \n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = TorchData(train_encodings, train_data.label)\n",
    "valid_dataset = TorchData(valid_encodings, val_data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_acc(labels, logits):\n",
    "    logits = np.round(logits)\n",
    "    cnt = 0\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == logits[idx]:\n",
    "            cnt += 1\n",
    "    return cnt / len(labels)\n",
    "\n",
    "def v_standard(labels, logits):\n",
    "    logits = np.round(logits)\n",
    "    v_vec = np.abs(np.log(logits + 1) - np.log(labels + 1))\n",
    "    \n",
    "    res = []\n",
    "    for v in v_vec:\n",
    "        if v <= 0.2:\n",
    "            res.append(1)\n",
    "        elif v <= 0.4:\n",
    "            res.append(0.8)\n",
    "        elif v <= 0.6:\n",
    "            res.append(0.6)\n",
    "        elif v <=0.8:\n",
    "            res.append(0.4)\n",
    "        elif v <= 1.0:\n",
    "            res.append(0.2)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def final_score(labels, logits):\n",
    "    ext_acc = exact_acc(labels, logits)\n",
    "    v = v_standard(labels, logits)\n",
    "    return np.sum(v) * 0.7 + ext_acc * 0.3\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    # smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "    score = final_score(labels, logits)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy the arguments for the trainer  \n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='./results',          \n",
    "    num_train_epochs = num_epochs,     \n",
    "    per_device_train_batch_size = 8,  # Can't be too big \n",
    "    per_device_eval_batch_size = 8,   \n",
    "    weight_decay = 0.01,               \n",
    "    learning_rate = 4e-5,\n",
    "    logging_dir = './logs',            \n",
    "    save_total_limit = 2,   # By setting this, we only save best and last model\n",
    "    load_best_model_at_end = True,     \n",
    "    metric_for_best_model = 'score',    \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\"\n",
    ")\n",
    "\n",
    "# Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,                         \n",
    "    args = training_args,                  \n",
    "    train_dataset = train_dataset,         \n",
    "    eval_dataset = valid_dataset,          \n",
    "    compute_metrics = compute_metrics_for_regression,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/best\n",
      "Configuration saved in results/best/config.json\n",
      "Model weights saved in results/best/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"results/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10001\n",
      "  Batch size = 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b070d95502413ab95a791aac965330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.0539069175720215,\n",
       " 'eval_mse': 4.053907871246338,\n",
       " 'eval_rmse': 2.0134317874908447,\n",
       " 'eval_mae': 1.176129698753357,\n",
       " 'eval_r2': 0.8123140847990389,\n",
       " 'eval_score': 6471.35090690931,\n",
       " 'eval_runtime': 74.5055,\n",
       " 'eval_samples_per_second': 134.232,\n",
       " 'eval_steps_per_second': 6.724,\n",
       " 'epoch': 24.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the summary\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Result for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = 'results/best/pytorch_model.bin'\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_50000</td>\n",
       "      <td>罪犯吴智信，男，1990年xx月xx日出生，汉族，小学文化，农民，原户籍所在地广西陆川县平乐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_50001</td>\n",
       "      <td>罪犯高九峰，男，1954年xx月xx日出生于福建省南安市，汉族，初中文化，现在福建省清流监狱...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_50002</td>\n",
       "      <td>罪犯罗被策，又名罗义成，男，1979年xx月xx日生，汉族，中专文化，湖南省衡阳县人，现在湖...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_50003</td>\n",
       "      <td>罪犯黄笑雪，男，1983年xx月xx日出生于湖南省龙山县，汉族，现在湖南省星城监狱服刑，以被...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_50004</td>\n",
       "      <td>罪犯曾先，男，1987年xx月xx日出生，汉族，四川省西昌市人，初中文化，现在四川省攀西监狱...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>id_74996</td>\n",
       "      <td>罪犯熊军，男，1971年xx月xx日生，汉族，湖北省仙桃市人，普通高中毕业，现在吉林省长春铁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>id_74997</td>\n",
       "      <td>罪犯张子，男，1976年xx月xx日出生于广西壮族自治区合浦县，汉族，小学文化，现在广西壮族...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>id_74998</td>\n",
       "      <td>罪犯曲义伯，女，1981年xx月xx日出生，汉族，出生地辽宁省大连市，中专文化，现在辽宁省女...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>id_74999</td>\n",
       "      <td>罪犯马被以，女，1979年xx月xx日出生于湖南省永顺县，土家族，初中文化。现在湖南省未成年...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>id_75000</td>\n",
       "      <td>罪犯黄孝冠，男，1967年xx月xx日出生，汉族，出生地黑龙江省北安市，大专文化，现在辽宁省...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               fact\n",
       "0      id_50000  罪犯吴智信，男，1990年xx月xx日出生，汉族，小学文化，农民，原户籍所在地广西陆川县平乐...\n",
       "1      id_50001  罪犯高九峰，男，1954年xx月xx日出生于福建省南安市，汉族，初中文化，现在福建省清流监狱...\n",
       "2      id_50002  罪犯罗被策，又名罗义成，男，1979年xx月xx日生，汉族，中专文化，湖南省衡阳县人，现在湖...\n",
       "3      id_50003  罪犯黄笑雪，男，1983年xx月xx日出生于湖南省龙山县，汉族，现在湖南省星城监狱服刑，以被...\n",
       "4      id_50004  罪犯曾先，男，1987年xx月xx日出生，汉族，四川省西昌市人，初中文化，现在四川省攀西监狱...\n",
       "...         ...                                                ...\n",
       "24996  id_74996  罪犯熊军，男，1971年xx月xx日生，汉族，湖北省仙桃市人，普通高中毕业，现在吉林省长春铁...\n",
       "24997  id_74997  罪犯张子，男，1976年xx月xx日出生于广西壮族自治区合浦县，汉族，小学文化，现在广西壮族...\n",
       "24998  id_74998  罪犯曲义伯，女，1981年xx月xx日出生，汉族，出生地辽宁省大连市，中专文化，现在辽宁省女...\n",
       "24999  id_74999  罪犯马被以，女，1979年xx月xx日出生于湖南省永顺县，土家族，初中文化。现在湖南省未成年...\n",
       "25000  id_75000  罪犯黄孝冠，男，1967年xx月xx日出生，汉族，出生地黑龙江省北安市，大专文化，现在辽宁省...\n",
       "\n",
       "[25001 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('data/testA.csv')\n",
    "\n",
    "# 截取掉第一句话\n",
    "# test_set['fact'] = test_set['fact'].map(lambda x: x[x.find('。') + 1:], na_action='ignore')\n",
    "\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(test_set.fact.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "test_dataset = TorchData(encodings, length=25001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 25001\n",
      "  Batch size = 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d1de8be4d34c449a24caca3cf87319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对测试数据预测，结果为浮点数\n",
    "pred_labels = trainer.predict(test_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('data/submission.csv')\n",
    "id_label_list = []\n",
    "\n",
    "for index,row in submit.iterrows():\n",
    "    idx = int(row['id'].replace(\"id_\", '')) - 50000\n",
    "    label = int(np.round(pred_labels[idx][0]))\n",
    "    id_label_list.append([row['id'], label])\n",
    "\n",
    "df = pd.DataFrame(data=id_label_list, columns=['id','label'])\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1ad28bcc00bbef288569d3f1a376da4d382e3330132777674284f995c8eb569"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
