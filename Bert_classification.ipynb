{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788c7525-ef5d-462b-8208-f91dea13f503",
   "metadata": {},
   "source": [
    "### Import Libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc36c033-ab95-4c49-a4bb-301e51957f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use only one GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee917cc-761b-4182-97cb-8b2356e4ea92",
   "metadata": {},
   "source": [
    "### Use Pre-trained bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfa88cb-7d29-408e-85df-f4460cf3cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext-large were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"hfl/chinese-roberta-wwm-ext-large\" # \"hfl/chinese-roberta-wwm-ext-large\" requires at least 16GB \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# By setting num_labels to 1 will automatically enable regression mode\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels = 32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db240690-4da5-4bdb-a30e-8d4e6da55bf1",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1eb5e2-5b87-42b4-ae89-021ecbdf6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/train.csv\"\n",
    "data = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d7620c-845b-4caa-9b6a-02db0720b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_truncate(text):\n",
    "    if len(text) <= 510:\n",
    "        return text\n",
    "    \n",
    "    return text[-511:-1]\n",
    "\n",
    "data['fact'] = [tail_truncate(t) for t in data.fact.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456be8ad-f5ed-4966-9012-4499df145d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: 0,\n",
       " 13: 1,\n",
       " 8: 2,\n",
       " 7: 3,\n",
       " 6: 4,\n",
       " 11: 5,\n",
       " 0: 6,\n",
       " 14: 7,\n",
       " 10: 8,\n",
       " 9: 9,\n",
       " 5: 10,\n",
       " 4: 11,\n",
       " 2: 12,\n",
       " 24: 13,\n",
       " 3: 14,\n",
       " 17: 15,\n",
       " 1: 16,\n",
       " 23: 17,\n",
       " 15: 18,\n",
       " 18: 19,\n",
       " 16: 20,\n",
       " 20: 21,\n",
       " 19: 22,\n",
       " 21: 23,\n",
       " 22: 24,\n",
       " 27: 25,\n",
       " 25: 26,\n",
       " 26: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 33: 30,\n",
       " 30: 31}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data.label.unique()\n",
    "\n",
    "label_dict = {}\n",
    "\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cf9100-9ffc-4c3f-9454-e56303a03c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id_0         0\n",
       "id_1         1\n",
       "id_2         2\n",
       "id_3         3\n",
       "id_4         4\n",
       "            ..\n",
       "id_49996     3\n",
       "id_49997    11\n",
       "id_49998    15\n",
       "id_49999    21\n",
       "id_50000     8\n",
       "Name: label, Length: 50001, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nlabel'] = data.label.replace(label_dict)\n",
    "\n",
    "data.nlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35aa6990-fa8b-47ef-a254-4ffbcac8e90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_30893</th>\n",
       "      <td>罪犯张都树，男，1994年xx月xx日出生，汉族，山西省浑源人，现在山西省太原第三监狱服刑，...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_45279</th>\n",
       "      <td>告人池杰犯运输毒品罪，判处有期徒刑十一年，并处罚金人民币一万元（已缴纳）。刑期自2017年x...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_16398</th>\n",
       "      <td>教所服刑，以被告人林凯利犯盗窃罪，判处有期徒刑八年，并处罚金人民币二万。服刑期间，发现漏罪。...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_13653</th>\n",
       "      <td>二年和并处罚金人民币五万元不变；于2019年xx月xx日作出（2019）桂02刑更845号刑...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_13748</th>\n",
       "      <td>x日投送扎兰屯监狱服刑。执行过程中，刑期无变动。截止2018年xx月xx日，剩余刑期十个月十...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_11284</th>\n",
       "      <td>伤害罪，判处有期徒刑三年六个月。该判决已发生法律效力，罪犯李伟于2017年xx月xx日入监服...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_44732</th>\n",
       "      <td>建议书报送本院审理。本院依法组成合议庭进行了审理，现已审理终结。 执行机关提出，罪犯欧九固在...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_38158</th>\n",
       "      <td>罪犯姜群，男，1971年xx月xx日出生，汉族，出生地辽宁省沈阳市，初中文化，现在辽宁省沈阳...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_860</th>\n",
       "      <td>1年xx月xx日起至2021年xx月xx日止。判决发生法律效力后于2012年xx月xx日交付...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_15795</th>\n",
       "      <td>月。2014年xx月xx日本院裁定减去有期徒刑一年一个月，剥夺政治权利八年不变。现执行机关黑...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       fact  label\n",
       "id                                                                \n",
       "id_30893  罪犯张都树，男，1994年xx月xx日出生，汉族，山西省浑源人，现在山西省太原第三监狱服刑，...      2\n",
       "id_45279  告人池杰犯运输毒品罪，判处有期徒刑十一年，并处罚金人民币一万元（已缴纳）。刑期自2017年x...      3\n",
       "id_16398  教所服刑，以被告人林凯利犯盗窃罪，判处有期徒刑八年，并处罚金人民币二万。服刑期间，发现漏罪。...      0\n",
       "id_13653  二年和并处罚金人民币五万元不变；于2019年xx月xx日作出（2019）桂02刑更845号刑...      4\n",
       "id_13748  x日投送扎兰屯监狱服刑。执行过程中，刑期无变动。截止2018年xx月xx日，剩余刑期十个月十...      3\n",
       "...                                                     ...    ...\n",
       "id_11284  伤害罪，判处有期徒刑三年六个月。该判决已发生法律效力，罪犯李伟于2017年xx月xx日入监服...      6\n",
       "id_44732  建议书报送本院审理。本院依法组成合议庭进行了审理，现已审理终结。 执行机关提出，罪犯欧九固在...      9\n",
       "id_38158  罪犯姜群，男，1971年xx月xx日出生，汉族，出生地辽宁省沈阳市，初中文化，现在辽宁省沈阳...      9\n",
       "id_860    1年xx月xx日起至2021年xx月xx日止。判决发生法律效力后于2012年xx月xx日交付...      0\n",
       "id_15795  月。2014年xx月xx日本院裁定减去有期徒刑一年一个月，剥夺政治权利八年不变。现执行机关黑...     10\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, train_size=0.8, random_state=42)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23544de3-59ca-486b-9464-2fea0b9d7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text\n",
    "train_encodings = tokenizer(train_data.fact.tolist(), truncation=True, padding=True, max_length=512)\n",
    "valid_encodings = tokenizer(val_data.fact.tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa146b74-dfef-44d9-941e-c65495b5ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it torch friendly\n",
    "class TorchData(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels = None, length = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        # If predicting then no label given\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "            item[\"labels\"] = int(item[\"labels\"])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.length is not None:\n",
    "            return self.length\n",
    "        \n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b3a3fc-a3d7-432e-bc9e-b1bbf75425f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = TorchData(train_encodings, train_data.nlabel)\n",
    "valid_dataset = TorchData(valid_encodings, val_data.nlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e1fc4-271f-42d1-bd99-fe4c53160f90",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99afd8e-b15e-437b-ae6d-1a724b0fa24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_acc(labels, logits):\n",
    "    cnt = 0\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == logits[idx]:\n",
    "            cnt += 1\n",
    "    return cnt / len(labels)\n",
    "\n",
    "def v_standard(labels, logits):\n",
    "    v_vec = np.abs(np.log(logits + 1) - np.log(labels + 1))\n",
    "    \n",
    "    res = []\n",
    "    for v in v_vec:\n",
    "        if v <= 0.2:\n",
    "            res.append(1)\n",
    "        elif v <= 0.4:\n",
    "            res.append(0.8)\n",
    "        elif v <= 0.6:\n",
    "            res.append(0.6)\n",
    "        elif v <=0.8:\n",
    "            res.append(0.4)\n",
    "        elif v <= 1.0:\n",
    "            res.append(0.2)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def final_score(labels, logits):\n",
    "    ext_acc = exact_acc(labels, logits)\n",
    "    v = v_standard(labels, logits)\n",
    "    return np.sum(v) * 0.7 + ext_acc * 0.3\n",
    "\n",
    "def compute_metrics_for_classification(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    flatten_logits = np.argmax(logits, axis=1).flatten()\n",
    "    flatten_labels = labels.flatten()\n",
    "    \n",
    "    print(\"logits:\", flatten_logits)\n",
    "    print(\"labels:\", flatten_labels)\n",
    "\n",
    "    v = v_standard(flatten_labels, flatten_logits)\n",
    "    ext_acc = exact_acc(flatten_labels, flatten_logits)\n",
    "    score = np.sum(v) * 0.7 + ext_acc * 0.3 # final_score(labels, logits)\n",
    "\n",
    "    return {\"v\": np.sum(v), \"ext_acc\": ext_acc, \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc8332-be32-4477-9b5c-fc66db401fd6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e250cee-3e5b-448e-8362-1c2ccb7c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "069936f8-ded3-43c2-8e7b-5918d5b136dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Specifiy the arguments for the trainer  \n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='./results',          \n",
    "    num_train_epochs = num_epochs,     \n",
    "    per_device_train_batch_size = 8,  # Can't be too big \n",
    "    per_device_eval_batch_size = 8,   \n",
    "    weight_decay = 0.01,               \n",
    "    learning_rate = 2e-5,\n",
    "    logging_dir = './logs',            \n",
    "    save_total_limit = 2,   # By setting this, we only save best and last model\n",
    "    load_best_model_at_end = True,     \n",
    "    metric_for_best_model = 'score',    \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\"\n",
    ")\n",
    "\n",
    "# Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,                         \n",
    "    args = training_args,                  \n",
    "    train_dataset = train_dataset,         \n",
    "    eval_dataset = valid_dataset,          \n",
    "    compute_metrics = compute_metrics_for_classification,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307cc277-0fdd-4661-a48e-82ee4f256919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820099e-28bb-4e90-8da2-1001154ccb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"results/best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29344604-cbb5-4277-ac44-0f65b255a9f0",
   "metadata": {},
   "source": [
    "### Get Result for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003807b-35ad-4cbe-aa5a-55e63966762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = 'results/best/pytorch_model.bin'\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f21e4a9-ba20-4726-b128-f7a690db477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('data/testA.csv')\n",
    "\n",
    "test_set['fact'] = [tail_truncate(t) for t in test_set.fact.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74edd4bd-c39c-43c1-82a4-7a609370448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(test_set.fact.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "test_dataset = TorchData(encodings, length=25001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1986c24-2b77-498a-9816-12ed0937dccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 25001\n",
      "  Batch size = 128\n"
     ]
    }
   ],
   "source": [
    "# 对测试数据预测，结果为浮点数\n",
    "pred_labels = trainer.predict(test_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0edd7d26-e407-4d4f-8be9-5367f63236ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_pred_labels = [np.argmax(labels).flatten()[0] for labels in pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7b63efa-a045-46cf-9c28-1c50adb9aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('data/submission.csv')\n",
    "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "id_label_list = []\n",
    "\n",
    "for index,row in submit.iterrows():\n",
    "    idx = int(row['id'].replace(\"id_\", '')) - 50000\n",
    "    label = label_dict_inverse[flatten_pred_labels[idx]]\n",
    "    id_label_list.append([row['id'], label])\n",
    "\n",
    "df = pd.DataFrame(data=id_label_list, columns=['id','label'])\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
